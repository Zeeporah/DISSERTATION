{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class UniversityRecommender:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.user_inputs = []\n",
    "        num_rec = None\n",
    "\n",
    "    def add_user_inputs(self, inputs):\n",
    "        self.user_inputs.extend(inputs)\n",
    "\n",
    "    def set_num_rec(self, num_rec):\n",
    "        self.num_rec = num_rec\n",
    "\n",
    "    # Recommend universities based on user inputs and return top k recommendations\n",
    "    def recommend(self, df):\n",
    "        recommended_all = []\n",
    "        actual_all = []\n",
    "        \n",
    "        for input in self.user_inputs:\n",
    "            course, max_fee, min_rank = input\n",
    "\n",
    "            # Filter dataset\n",
    "            filtered_df = df[(df['course'] == course) & \n",
    "                             (df['average_fee'] <= max_fee) &\n",
    "                             (df['uk_rank'] <= min_rank)]\n",
    "            \n",
    "            # Calculate similarity\n",
    "            features = ['uk_rank', 'average_fee']\n",
    "            X = filtered_df[features].values  \n",
    "            similarity = cosine_similarity(X)\n",
    "            \n",
    "            # Get top k indices of filtered dataset\n",
    "            indices = filtered_df.index.values\n",
    "            sim_scores = list(enumerate(similarity))\n",
    "            top_indices_filtered = sorted(sim_scores, key=lambda x: x[1][indices[0]], reverse=True)[:self.num_rec]\n",
    "            \n",
    "            # Recommend\n",
    "            recommended_names = filtered_df['university'].iloc[[index[0] for index in top_indices_filtered]]\n",
    "            recommended_all.append(list(recommended_names))\n",
    "            \n",
    "            # Get top k indices of original dataset\n",
    "            top_indices_original = sorted(sim_scores, key=lambda x: x[1][indices[0]], reverse=True)[:self.num_rec]\n",
    "            \n",
    "            # Actual\n",
    "            actual_all.append(filtered_df['university'].head(self.num_rec).tolist())\n",
    "            \n",
    "        return recommended_all, actual_all\n",
    "\n",
    "    # Mean Average Precision\n",
    "    def map(self, actual, predicted):\n",
    "        map_scores = []\n",
    "        for i in range(len(actual)):\n",
    "            map_scores.append(self.avg_precision(actual[i], predicted[i], self.num_rec))\n",
    "        return np.mean(map_scores)\n",
    "    \n",
    "    # Average Precision \n",
    "    def avg_precision(self, actual, predicted, n):\n",
    "\n",
    "        actual_set = set(actual)\n",
    "        predicted_set = set(predicted[:n])\n",
    "    \n",
    "        common = actual_set.intersection(predicted_set)\n",
    "\n",
    "        num_relevant = len(common)\n",
    "        if len(predicted_set) > n:\n",
    "            precision = num_relevant / n\n",
    "        else:\n",
    "            precision = num_relevant / len(predicted_set)\n",
    "\n",
    "        return precision\n",
    "    \n",
    "    # Normalized Discounted Cumulative Gain\n",
    "    def ndcg(self,actual, predicted):\n",
    "        # Calculate DCG\n",
    "        dcg = 0\n",
    "        idcg = 0\n",
    "        for i, p in enumerate(predicted[:self.num_rec]):\n",
    "            if p in actual:\n",
    "                rel = 1\n",
    "            else:\n",
    "                rel = 0    \n",
    "            dcg += (2**rel - 1) / math.log2(i+2)    \n",
    "        \n",
    "        # Calculate IDCG\n",
    "        ideal_predicted = actual[:self.num_rec]\n",
    "        for i, p in enumerate(ideal_predicted):\n",
    "            rel = 1\n",
    "            idcg += (2**rel - 1) / math.log2(i+2)\n",
    "        if idcg == 0:\n",
    "            return 0\n",
    "        ndcg = dcg / idcg\n",
    "        return ndcg\n",
    "    \n",
    "    # Mean Reciprocal Rank\n",
    "    def mrr(self, actual, predicted):\n",
    "        rr_scores = []\n",
    "        for i in range(len(actual)):\n",
    "            act_list = actual[i] \n",
    "            pred_list = predicted[i]\n",
    "        \n",
    "            reciprocal_rank = 0\n",
    "            if pred_list[0] == act_list[0]:\n",
    "                reciprocal_rank = 1\n",
    "            rr_scores.append(reciprocal_rank)\n",
    "        return np.mean(rr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: [['University of St Andrews', 'Lancaster University', 'University of Bath', 'University of Exeter', 'University of Leeds']]\n",
      "Predicted: [['University of Nottingham', 'University of Southampton', 'Royal Holloway, University of London', 'University of Glasgow', 'University of Leeds']]\n",
      "MAP Score:  0.2\n",
      "NDCG 1: 0.13120507751234178\n",
      "MRR Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset.csv\") \n",
    "recommender = UniversityRecommender()\n",
    "\n",
    "# Set number of recommendations\n",
    "recommender.set_num_rec(5)  \n",
    "\n",
    "# Add user inputs\n",
    "#recommender.add_user_inputs([['Computing', 30000, 25],['Social Sciences', 28000, 30],['Engineering and Technology', 35000, 35]]) \n",
    "recommender.add_user_inputs([['Business & Management Studies', 24000, 21]])\n",
    "# Get recommendations\n",
    "predicted, actual = recommender.recommend(df)\n",
    "\n",
    "# Print the results\n",
    "print(\"Actual:\", actual)\n",
    "print(\"Predicted:\", predicted)\n",
    "\n",
    "# Evaluate and Print MAP\n",
    "map_score = recommender.map(actual, predicted)\n",
    "print(\"MAP Score: \", map_score)\n",
    "\n",
    "# Evaluate and Print NDCG\n",
    "for i in range(len(actual)):\n",
    "    ndcg = recommender.ndcg(actual[i], predicted[i])\n",
    "    print(f\"NDCG {i+1}: {ndcg}\")\n",
    "\n",
    "# Evaluate and Print MRR\n",
    "mrr_score = recommender.mrr(actual, predicted)\n",
    "print(\"MRR Score:\", mrr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
